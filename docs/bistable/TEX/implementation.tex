\chapter{implementation}\label{sec:implementation}

- First approach
	* Downloaded from MINA the latest version of QCADesigner, NOT COMPILES!
	* At first, lot of work done to obtain a working batch simulator on CPU
	* Meanwhile analisys of the code, location of possible bottlenecks, analisys of data structures and their possible transformation in order to obtain best explotation of CUDA
	* Batch simulator on CPU ready -> start profiling (table) and location of bottleneck.
- CUDA implementation
	* CPU algorithm -> CUDA algorithm proposed (working on old values each iteration, with Konrad's blessing): pseudo code.
	* After first implementation: wrong results, cells' polarizations don't converge, oscillations.
	-> Bistable approximations doesn't work with this algorithm.
	-> Solution: Don't change CPU algorithm -> don't compute neighbour cells values simultaneously.
	-> parallelization? Coloring algorithm
	-> randomization? randomize color order each sample
	* Cuda main data structures: arrays of polarizations, neighborhood, clocks, kink energies, stability.
	* Memory occupation on global, coalescent accesses, only one vector for old and new polarization
	* Constant memory, variables
	* shared memory for arrays of indexes of inputs and outputs (many accesses during kernel execution)
	* Moved clock values and input values calculation (only when they change) inside the kernel
	* Memory transfers
	* Fast math and float for faster approximation (only one double FU per SM)
	* Compulsory divergence reading neighbours
- Discussion pre-results on core simulation:
	* Iterations per sample: ca. 5-10
	* Colors: ca. 15-20
	* Number of samples: 2000*2^number_of_inputs
	* On CPU complexity: O(samples x mean iterations per sample x cells) ~ O(2000*2^Ninput x 10 x Ncells) = O(C*2^N)
	* Max (theoretical) speedup achievable = cells/colors -> O(sample x mean iterations per sample x colors) ~ O(2000*2^Ninputs x 10 x 15) = O(2^N)
	-> Technology constraints:
	* Memory transfers:
		 each iteration: device->host, stability: cells x 1 byte
		 each sample: device->host, outputs: number_of_outputs x 8 bytes
		 main_kernel calls: samples x mean iterations per sample x colors
		 update inputs kernel calls: 2 x 2^number_of_inputs (once every 1000 samples)
		 main kernel:
			- 1 global coalescent -> shared : number_of_outputs x 8 bytes (output_indexes)
			- 3 x global read coalescent : 3 x number_of_cells x 4 bytes (neighbours, cells_colors, cells_clock)
			--- for cycle: ( 2 coalescent + 1 random ) x max number of neighbours -> big divergency
			- 1 gloabal read + 2 global write coalescent: number_of_cells x (8 + 1 + 8) bytes (polarization, stability, polarization)
			- number_of_outputs reads in shared
			- write on global non coalescent
		 transfer rate?